---
title: 'Animaltracker Data Validation: New Mexico Data'
author: 
  - Joe Champion, Boise State University, joechampion@boisestate.edu
  - Thea Sukianto, Boise State University
date: May 27, 2020
output:
  pdf_document: default
  html_document: default
---

This document analyzes the results of the `animaltracker` package's data cleaning procedures by comparing a sample of 8 data sets processed by the `R` package to the same data manually processed with Microsoft Excel.

The cleaning process uses flag-based rules for discarding cases (rows) of data. 

- If measured rate of travel exceeds 84 m/min, mark the case with a `RateFlag`.

- If course change exceeds 100 degrees, mark the case with a `CourseFlag`.

- If measured distance traveled exceeds 840 m, mark the case with a `DistanceFlag`.

- Only keep cases without a `DistanceFlag` AND less than 2 flags.

**Note**: Throughout this report, the suffix `x` indicates data cleaned by `animaltracker`, and `y` indicates manually cleaned data.

# Preliminaries

For reproducibility, configure and load required `R` packages, including `animaltracker`.
```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```
```{r message=FALSE, warning= FALSE}
library(dplyr)
library(ggplot2)
library(tidyr)
library(animaltracker)
library(psych)
library(caret)

```

## Read and Prepare Data

Load the **manually** cleaned data (reshaping for consistent column names), then directly read and process the raw data using the **`animaltracker`** app.
```{r message=FALSE, warning = FALSE}
###  load MANUALLY cleaned data, reshape for consistency
clean_manual <- read.csv("nm_validate/MastersheetNM - combined corrections applied.csv",
                             stringsAsFactors = FALSE, 
                             na.strings =c("", "#VALUE!", "NA", "#N/A","#DIV/0!" )) %>%
  filter(!is.na(Date), !is.na(Cow)) %>%
  rename(CourseDiff = coursedifference, TimeDiff = timedifference, 
     TimeDiffMins = timedifference.in.minutes,
     RateFlag = ratestatement, CourseFlag = coursestatement,
     DistFlag = distancestatement, TotalFlags = total, Keep = statement) %>%
  mutate(
     Index = as.numeric(Index),
     Altitude = as.numeric(Altitude),
     DateTime = paste(Date, Time),
     Keep = 1*!Keep, # ew 
     ## fix undefined / missing flags
     RateFlag = replace_na(RateFlag, 1),
     CourseFlag = replace_na(CourseFlag, 1),
     DistFlag = replace_na(DistFlag, 1),
     TotalFlags = ifelse(is.na(TotalFlags), RateFlag+CourseFlag+DistFlag, TotalFlags), 
     Keep = replace_na(Keep, 0) 
 )

### read and CLEAN the raw data with the animaltracker app
folder_rawdata <- "../test_data/DeepWell_2018_Collar_Raw"
nm_files <- list.files(folder_rawdata)
aniid <- as.integer(gsub("DW_(\\d{3})(.*)", "\\1", nm_files))
gpsid <- as.integer(gsub("DW_(\\d{3})_(\\d{2})(.*)", "\\2", nm_files))

clean_anitracker <- lapply(1:length(nm_files), function(i){
    df_raw <- read.csv(file.path(folder_rawdata, nm_files[i]))
    df_clean_animaltracker <- clean_location_data(df_raw, 
                                  dtype = "igotu", filters = FALSE, maxtime =150,
                                  aniid = aniid[i], gpsid = gpsid[i])
  }) %>% 
  do.call(rbind, .) %>% 
  rename(Cow = Animal) %>%
  type.convert()

```
Next, merge the cleaned data from `animaltracker` (`r nrow(clean_anitracker)` rows, `r ncol(clean_anitracker)` columns) with the manually cleaned data (`r nrow(clean_manual)` rows, `r ncol(clean_manual)` columns). 

Rows are matched by the combination of `Cow`, `Index` (uniquely identifies almost all rows) and `Altitude` (to break ties in rare duplicates). 
```{r}
clean_anitracker <- clean_anitracker %>% 
  arrange(Cow, Index, Altitude) %>% 
  mutate(merge_index = 1:n())

clean_manual <- clean_manual %>% 
  arrange(Cow, Index, Altitude) %>% 
  mutate(merge_index = 1:n())

join <- full_join(clean_anitracker, clean_manual, by="merge_index") %>%
  rename( MegaRateFlag.x = MegaRateFlag) %>% 
  mutate( Cow = factor(Cow.x))
```

The merged data has `r nrow(join)` rows.

# Analysis

## Overall Agreement
First, we compare the results of cleaning the data within `animaltracker` (via the `clean_location_data` function) to results of manual cleaning via spreadsheet.
```{r include=FALSE}
keepxtab <- with(join, table(Keep.x, Keep.y))
```
The cleaning methods agree in `r round(100*sum(diag(keepxtab))/sum(keepxtab),3)`% of cases, except for `r keepxtab[2,1]` cases (`r round(100*keepxtab[2,1]/sum(keepxtab),3)`%) kept by `animaltracker` but discarded by manual processing and `r keepxtab[1,2]` cases (`r round(100*keepxtab[1,2]/sum(keepxtab),3)`%) kept by manual processing but discarded by `animaltracker`. 

The relatively low number of discarded points in the data set suggests a need for careful analysis. The following confusion matrix and associated statistics provides details.
```{r}
confusionMatrix(factor(join$Keep.x, labels = c( "discard", "keep")), 
                factor(join$Keep.y, labels = c( "discard", "keep")), 
                positive = "keep", dnn = c("animaltracker", "manual"), 
                mode="everything")
```


## Analysis of Cases with Different Results

All of the cases kept by manual processing (n = `r keepxtab[1,2]`) but discarded by `animaltracker` were marked with a **rate flag** by `animaltracker`, but not manual. 
```{r}
manual_keep <- join %>% 
  filter(Keep.x < Keep.y) %>% 
  select(ind = merge_index, Cow, DateTime = DateTime.x, TimeDiffMins = TimeDiffMins.x, 
              Rate.x, Rate.y, RateFlag.x, RateFlag.y, 
              Dist.x = Distance.x, Dist.y = Distance.y, DistFlag.x, DistFlag.y,
              CourseDiff.x, CourseDiff.y, CourseFlag.x, CourseFlag.y) 

manual_keep %>% 
  summarise(RateFlag.x = sum(RateFlag.x),
                   CourseFlag.x = sum(CourseFlag.x),
                   DistFlag.x = sum(DistFlag.x),
                   RateFlag.y = sum(RateFlag.y),
                   CourseFlag.y = sum(CourseFlag.y),
                   DistFlag.y = sum(DistFlag.y)) %>% 
  tidyr::gather("Flag", "Count") %>% 
  mutate(Source = ifelse(grepl(".x", Flag), "animaltracker", "manual"),
                Flag = substr(Flag, 1, nchar(Flag)-2)) %>%
  ggplot( aes(Flag, Count, fill = Source)) +
  geom_bar(stat = "identity", position = "dodge") +
  ggtitle(paste0("Observations Kept by Manual Processing, 
                 discarded by Animaltracker\n","N = ",nrow(manual_keep)) )
```
```{r}
manual_keep %>% head(10) # first several cases
```
All of the cases kept by `animaltracker` but discarded by manual processing (n = `r keepxtab[2,1]`) were marked with a **distance flag** by manual processing, but not `animaltracker`. 
```{r}
anitracker_keep <- join %>% 
  filter(Keep.x > Keep.y) %>% 
  select(ind = merge_index, Cow, DateTime = DateTime.x, TimeDiffMins = TimeDiffMins.x, 
              Rate.x, Rate.y, RateFlag.x, RateFlag.y, 
              Dist.x = Distance.x, Dist.y = Distance.y, DistFlag.x, DistFlag.y,
              CourseDiff.x, CourseDiff.y, CourseFlag.x, CourseFlag.y) 

anitracker_keep %>% 
  summarise(RateFlag.x = sum(RateFlag.x),
                   CourseFlag.x = sum(CourseFlag.x),
                   DistFlag.x = sum(DistFlag.x),
                   RateFlag.y = sum(RateFlag.y),
                   CourseFlag.y = sum(CourseFlag.y),
                   DistFlag.y = sum(DistFlag.y)) %>% 
  tidyr::gather("Flag", "Count") %>% 
  mutate(Source = ifelse(grepl(".x", Flag), "animaltracker", "manual"),
                Flag = substr(Flag, 1, nchar(Flag)-2)) %>%
  ggplot( aes(Flag, Count, fill = Source)) +
  geom_bar(stat = "identity", position = "dodge") +
  ggtitle(paste0("Observations Kept by AnimalTracker, 
                 discarded by Manual Processing\n","N = ",nrow(anitracker_keep)) )
```
```{r}
anitracker_keep %>% head(10) # first several cases
```

## Effects of Cleaning Differences on Outcome Measures

The remaining analysis addresses the statistical effects of the processing errors on key outcomes.

### Cumulative Distance (per day)

The time series plots below indicate a very close conformity between the data cleaned in `animaltracker` and the manually cleaned data.

```{r}
cumdist <- join %>% 
  group_by(Cow) %>% 
  arrange(merge_index) %>% 
  mutate(Dist.y = lag(Distance.y,1), 
                cumDist.x = cumsum(replace_na(Distance.x,0)),
                cumDist.y = cumsum(replace_na(Distance.y,0))) %>%
  ungroup()

cumdist_anitracker <- cumdist %>% 
  group_by(Cow) %>% arrange(merge_index) %>%
  mutate(index = 1:n()) %>% ungroup() %>%
  ungroup() %>%
  select(Cow, index, cumDist.x, DistFlag.x) %>% 
  rename(Flag = DistFlag.x,
                cumDist = cumDist.x) %>% 
  mutate(Source = "animaltracker")

cumdist_manual <- cumdist %>% 
  group_by(Cow) %>% arrange(merge_index) %>%
  mutate(index = 1:n()) %>% ungroup() %>%
  select( index, Cow, cumDist.y, DistFlag.y) %>% 
  rename( Flag = DistFlag.y,
                cumDist = cumDist.y) %>% 
  mutate(Source = "manual")

plot_data <- bind_rows(cumdist_anitracker, cumdist_manual)

ggplot(plot_data, aes(x=index, y=cumDist, group=Source, color=Source)) +
  geom_line(aes(size = Source)) +
  ylab("Cumulative Distance") +
  scale_color_discrete(guide = guide_legend(reverse = TRUE)) +
  scale_size_manual(values=c(2, 1)) +
  facet_wrap(vars(Cow)) +
  theme(axis.text.x = element_text(angle = -45))
```

### Relative Error of Cumulative Distance Estimates

The following summarizes the relative error of cumulative distances calculated from the `animaltracker` app in comparison to the manually processed data.

```{r}
error_cumdist <- join %>%
  group_by(Cow) %>% 
  arrange(merge_index) %>%
  mutate(
    Dist.y = lag(Distance.y,1), 
    cumDist.x = cumsum(replace_na(Distance.x,0)),
    cumDist.y = cumsum(replace_na(Dist.y,0)) ) %>% 
  group_by(Cow, Date.x) %>%
  summarize(
    cumDist.x = sum(cumDist.x, na.rm=TRUE),
    cumDist.y = sum(cumDist.y, na.rm = TRUE),
    cumDist.relerror = (cumDist.x-cumDist.y)/cumDist.y
  ) %>% 
  ungroup() 
```

Based on N = `r nrow(error_cumdist)` days of data, the overall relative error rate in cumulative distance per day is `r round(100*mean(error_cumdist$cumDist.relerror),2)`%.

```{r}
ggplot(error_cumdist, aes(x = Cow, y = cumDist.relerror, fill = Cow))+
    geom_violin(trim=TRUE)+
    geom_point()+
    scale_y_continuous(trans='log10')

error_cumdist %>%
  group_by(Cow) %>% 
  mutate(index = 1:n()) %>% 
  ungroup() %>%
  select(index, name = Cow, value = cumDist.relerror) %>% 
  mutate(name = paste0("Cow_", name)) %>%
  pivot_wider() %>% 
  select(-index) %>%
  psych::describe() %>%
  select(n, mean, sd, median, range, se ) %>%
  print(digits = 4)

```

### Rate of Travel

The following describes differences in estimated `Rate` measurements (meters/min) between the data cleaned in `animaltracker` and the manually cleaned data.

```{r}
rates_keep <- join %>% 
    filter(Keep.x > 0 ) %>%
    select(merge_index, Rate = Rate.x) %>% 
    mutate(source = "animaltracker") %>%
  rbind(
    join %>% 
      filter(Keep.y > 0) %>%
      select(merge_index, Rate = Rate.y) %>%
      mutate(source = "manual")
  ) %>%
  mutate(source = factor(source),
         Rate = as.numeric(Rate))

rates_keep %>%
  pivot_wider(names_from = "source", values_from="Rate") %>%
  select(-merge_index) %>%
  psych::describe() %>%
  select(n, mean, sd, median, range, se ) %>%
  print(digits = 3)
  
```

```{r warning = FALSE, message = FALSE}
ggplot(rates_keep, aes(x = source, y = Rate, fill = source))+
  geom_violin(trim=TRUE) +
  theme_minimal()
```

Restricting to the bulk of measured rates (< 40 meters/min), we see nearly identical distributions.
```{r}
ggplot(rates_keep %>% filter(Rate < 40), aes(x = source, y = Rate, fill = source))+
  geom_violin(trim=TRUE) +
  theme_minimal()
```